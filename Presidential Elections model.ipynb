{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Election_model-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiabj/03-presidential-election/blob/master/Presidential%20Elections%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPjGtf_toU9C"
      },
      "source": [
        "!python -m pip install --user --upgrade pip\n",
        "\n",
        "!pip3 install pandas==0.23.4 matplotlib==3.0.3 scipy==1.2.1 scikit-learn==0.22  --user"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnaIt63ZoU9a"
      },
      "source": [
        "!pip3 install kfp --upgrade --user"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML-6n27zoU96"
      },
      "source": [
        "!which dsl-compile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9niS-nZeoU-H"
      },
      "source": [
        "import kfp\n",
        "import kfp.dsl as dsl\n",
        "import kfp.components as comp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYuCRlEBoU-R"
      },
      "source": [
        "out_dir = \"/home/jovyan/Artificial-Neural-Network/data/out/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff5DYDO2oU-f"
      },
      "source": [
        "def train(data_path, model_file):\n",
        "    \n",
        "    import pickle\n",
        "    import sys, subprocess;\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    \n",
        "    import os\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import recall_score, accuracy_score\n",
        "    \n",
        "    df = pd.read_csv('https://github.com/sophiabj/03-presidential-election/blob/master/data/president-1976-2016.csv')\n",
        "    new_dataframe = df[(df.party=='republican') + (df.party =='democrat')]\n",
        "    \n",
        "    new_dataframe.drop(['state_ic','notes','state','state_po', 'office','writein','candidate'],inplace=True, axis = 1)\n",
        "    \n",
        "    X = new_dataframe.drop('party', axis=1)\n",
        "    y = new_dataframe['party']\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "    \n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    normalised_train_df = scaler.fit_transform(x_train)\n",
        "    normalised_train_df = pd.DataFrame(normalised_train_df, columns=x_train.columns)\n",
        "\n",
        "    normalised_test_df = scaler.transform(x_test)\n",
        "    normalised_test_df = pd.DataFrame(normalised_test_df, columns=x_train.columns)\n",
        "\n",
        "\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(normalised_train_df, y_train)\n",
        "    \n",
        "    \n",
        "     #output file to path\n",
        "    np.savez_compressed(f'{data_path}/preprocessed-data.npz', \n",
        "                       xtrain=normalised_train_df,\n",
        "                       xtest=normalised_test_df,\n",
        "                       ytrain=y_train,\n",
        "                       ytest=y_test)\n",
        "    print(\"Preprocessing Done\")\n",
        "\n",
        "     #Save the model to the designated \n",
        "    with open(f'{data_path}/{log_reg_file}', 'wb') as file:\n",
        "        pickle.dump(Log_reg, file)\n",
        "        \n",
        "    print(\"Model Trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAvBnD5RoU--",
        "outputId": "f124f1c9-c72c-447e-ab21-207199bb32a4"
      },
      "source": [
        "def predict(data_path, model_file):\n",
        "    \n",
        "    import pickle\n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import recall_score, accuracy_score\n",
        "    \n",
        "    with open(f'{data_path}/{log_reg_file}','rb') as file:\n",
        "        log_reg = pickle.load(file)\n",
        "\n",
        "    # Load and unpack the test_data\n",
        "   preprocessed_data = np.load(f'{data_path}/preprocessed-data.npz')\n",
        "    x_test = preprocessed_data['xtest']\n",
        "    y_test = preprocessed_data['ytest']\n",
        "\n",
        "    #Evaluate the model and print results\n",
        "     log_reg_pred = log_reg.predict(x_test)\n",
        "    \n",
        "   print('Model \\nAccuracy score = {} \\nF1_score = {}' .format(accuracy_score(y_test, log_reg_pred), f1_score(y_test, log_reg_pred)))\n",
        "    \n",
        "    #np.savetxt(f'{data_path}/model_result.txt', clf_pred, fmt='%1.2f')\n",
        "    with open(f'{data_path}/model_result.txt', 'w') as result:\n",
        "        result.write(\" Prediction: {},\\nActual: {} \".format(log_reg_pred,y_test))\n",
        "    \n",
        "    print('Prediction has been saved successfully!')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 70 101]\n",
            " [ 79  87]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4BapMR0oU_b"
      },
      "source": [
        "train_op = comp.func_to_container_op(train , base_image = \"python:3.7-slim\")\n",
        "predict_op = comp.func_to_container_op(predict , base_image = \"python:3.7-slim\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrsb7SYeoU_r"
      },
      "source": [
        "client = kfp.Client()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIhB1Q9hoU_1"
      },
      "source": [
        "# Define the pipeline\n",
        "@dsl.pipeline(\n",
        "   name='Presidential Elections Pipeline',\n",
        "   description='An ML pipeline that predicts outcome of presidential elections.'\n",
        ")\n",
        "\n",
        "# Define parameters to be fed into pipeline\n",
        "def presidential_election_pipeline(\n",
        "    data_path: str,\n",
        "    log_reg_file: str\n",
        "):\n",
        "    \n",
        "    # Define volume to share data between components.\n",
        "    vop = dsl.VolumeOp(\n",
        "    name=\"create_volume\",\n",
        "    resource_name=\"data-volume\", \n",
        "    size=\"1Gi\", \n",
        "    modes=dsl.VOLUME_MODE_RWO)\n",
        "    \n",
        "    # Create presidential elections training component.\n",
        "    presidential_elections_training_container = train_op(data_path, model_file) \\\n",
        "                                    .add_pvolumes({data_path: vop.volume})\n",
        "\n",
        "    # Create presidential elections prediction component.\n",
        "    presidential_elections_predict_container = predict_op(data_path, model_file) \\\n",
        "                                    .add_pvolumes({data_path: presidential_elections_training_container.pvolume})\n",
        "    \n",
        "    # Print the result of the prediction\n",
        "    presidential_elections_result_container = dsl.ContainerOp(\n",
        "        name=\"print_prediction\",\n",
        "        image='library/bash:4.4.23',\n",
        "        pvolumes={data_path: presidential_elections_predict_container.pvolume},\n",
        "        arguments=['cat', f'{data_path}/result.txt']\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZvGbCBKoVAB"
      },
      "source": [
        "DATA_PATH = '/mnt'\n",
        "MODEL_PATH='presidential_elections_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87kVCm52oVAO"
      },
      "source": [
        "pipeline_func = presidential_elections_container_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRIDytHioVAg"
      },
      "source": [
        "run_name = pipeline_func.__name__ + ' run'\n",
        "\n",
        "arguments = {\"data_path\":DATA_PATH,\n",
        "             \"model_file\":MODEL_PATH}\n",
        "\n",
        "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
        "kfp.compiler.Compiler().compile(pipeline_func,  \n",
        "  '{}.zip'.format(experiment_name))\n",
        "\n",
        "# Submit pipeline directly from pipeline function\n",
        "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
        "                                                  experiment_name=experiment_name, \n",
        "                                                  run_name=run_name, \n",
        "                                                  arguments=arguments)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}