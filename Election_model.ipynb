{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Election_model-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiabj/03-presidential-election/blob/master/Election_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPjGtf_toU9C",
        "outputId": "10d75595-7995-49ca-b23e-017fa5d74c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        }
      },
      "source": [
        "!python -m pip install --user --upgrade pip\n",
        "\n",
        "!pip3 install pandas==0.23.4 matplotlib==3.0.3 scipy==1.2.1 scikit-learn==0.22  --user"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/5f/528232275f6509b1fff703c9280e58951a81abe24640905de621c9f81839/pip-20.2.3-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.6 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed pip-20.2.3\n",
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
            "Collecting pandas==0.23.4\n",
            "  Downloading pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 2.8 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.0.3\n",
            "  Downloading matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0 MB 43.3 MB/s \n",
            "\u001b[?25hCollecting scipy==1.2.1\n",
            "  Downloading scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22\n",
            "  Downloading scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas==0.23.4) (1.15.0)\n",
            "Installing collected packages: pandas, matplotlib, scipy, scikit-learn\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "xarray 0.15.1 requires pandas>=0.25, but you'll have pandas 0.23.4 which is incompatible.\n",
            "umap-learn 0.4.6 requires scipy>=1.3.1, but you'll have scipy 1.2.1 which is incompatible.\n",
            "tensorflow 2.3.0 requires scipy==1.4.1, but you'll have scipy 1.2.1 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you'll have pandas 0.23.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.0.3 pandas-0.23.4 scikit-learn-0.22 scipy-1.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnaIt63ZoU9a",
        "outputId": "fca32468-617e-43cd-ce55-260beaebe45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install kfp --upgrade --user"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
            "Collecting kfp\n",
            "  Downloading kfp-1.0.3.tar.gz (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.18.1)\n",
            "Collecting kubernetes<12.0.0,>=8.0.0\n",
            "  Downloading kubernetes-11.0.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.17.2)\n",
            "Collecting requests_toolbelt>=0.8.0\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.3.0)\n",
            "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
            "  Downloading kfp-server-api-1.0.3.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 628 kB/s \n",
            "\u001b[?25hCollecting jsonschema>=3.0.1\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from kfp) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from kfp) (7.1.2)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting strip-hints\n",
            "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
            "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.15.0)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
            "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 19.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (20.2.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.17.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel in /usr/local/lib/python3.6/dist-packages (from strip-hints->kfp) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp) (1.52.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp) (3.12.4)\n",
            "Building wheels for collected packages: kfp, kfp-server-api, strip-hints\n",
            "  Building wheel for kfp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kfp: filename=kfp-1.0.3-py3-none-any.whl size=159872 sha256=7051e2af2e17d946ba51c5d568754a726156ecf82f8cf255c5197ff3900513b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/17/2a/f0aa226d91bef376b3c97933112e9f341415ccd2488863343b\n",
            "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kfp-server-api: filename=kfp_server_api-1.0.3-py3-none-any.whl size=104114 sha256=5f3426eed5a2f4319c95370aa2710f2ed064af75644dad3af327df95c72c1b1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/a7/2f/fd95aed780d5bba7ccc7bbfb937f0aca7bf83cc2222c0155c6\n",
            "  Building wheel for strip-hints (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20994 sha256=0523b112e0e84a59b9e43976f3b8877a7c349e79b599be9649cac830791c14ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/6d/fa/7ed7c0560e1ef39ebabd5cc0241e7fca711660bae1ad752e2b\n",
            "Successfully built kfp kfp-server-api strip-hints\n",
            "Installing collected packages: websocket-client, kubernetes, requests-toolbelt, kfp-server-api, jsonschema, Deprecated, strip-hints, kfp\n",
            "\u001b[33m  WARNING: The script jsonschema is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script strip-hints is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts dsl-compile and kfp are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "nbclient 0.5.0 requires jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.10 jsonschema-3.2.0 kfp-1.0.3 kfp-server-api-1.0.3 kubernetes-11.0.0 requests-toolbelt-0.9.1 strip-hints-0.1.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML-6n27zoU96"
      },
      "source": [
        "!which dsl-compile"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9niS-nZeoU-H"
      },
      "source": [
        "import kfp\n",
        "import kfp.dsl as dsl\n",
        "import kfp.components as comp"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYuCRlEBoU-R"
      },
      "source": [
        "out_dir = \"/home/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff5DYDO2oU-f"
      },
      "source": [
        "def train(data_path, model_file):\n",
        "    \n",
        "    import pickle\n",
        "    import sys, subprocess;\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    \n",
        "    import os\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    from sklearn.multioutput import MultiOutputRegressor\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    from sklearn import metrics\n",
        "    \n",
        "    df = pd.read_csv('https://github.com/sophiabj/03-presidential-election/blob/master/data/usa-2016-presidential-election-by-county.csv')\n",
        "\n",
        "    new_dataframe = df[['Asian','At Least High School Diploma','Black','Child.Poverty.living.in.families.below.the.poverty.line',\n",
        "                      'Democrats 08 (Votes)','Democrats 12 (Votes)','Democrats 2008','Democrats 2012','Graduate Degree',\n",
        "                      'Nearest County','Poverty.Rate.below.federal.poverty.threshold','Republicans 08 (Votes)',\n",
        "                      'Republicans 12 (Votes)','Republicans 2008','Republicans 2012','Total Population','Votes',\n",
        "                      'White','White  Asian','total08','total12','total16', 'Democrats 2016', 'Republicans 2016']]\n",
        "    \n",
        "    \n",
        "    \n",
        "    X = new_dataframe.drop(columns=['Democrats 2016', 'Republicans 2016'])\n",
        "    y = new_dataframe[['Democrats 2016', 'Republicans 2016']]\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "    \n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    normalised_train_df = scaler.fit_transform(x_train)\n",
        "    normalised_train_df = pd.DataFrame(normalised_train_df, columns=x_train.columns)\n",
        "\n",
        "    normalised_test_df = scaler.transform(x_test)\n",
        "    normalised_test_df = pd.DataFrame(normalised_test_df, columns=x_train.columns)\n",
        "\n",
        "\n",
        "    max_depth = 30\n",
        "    regr_multirf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100,\n",
        "    max_depth=max_depth,\n",
        "    random_state=0))\n",
        "    regr_multirf.fit(normalised_train_df, y_train)\n",
        "\n",
        "    regr_rf = RandomForestRegressor(n_estimators=100, max_depth=max_depth,\n",
        "    random_state=2)\n",
        "    regr_rf.fit(normalised_train_df, y_train)\n",
        "    \n",
        "    \n",
        "     #output file to path\n",
        "    np.savez_compressed(f'{data_path}/preprocessed-data.npz', \n",
        "                       xtrain=normalised_train_df,\n",
        "                       xtest=normalised_test_df,\n",
        "                       ytrain=y_train,\n",
        "                       ytest=y_test)\n",
        "    print(\"Preprocessing Done\")\n",
        "\n",
        "     #Save the model to the designated \n",
        "    with open(f'{data_path}/{log_reg_file}', 'wb') as file:\n",
        "        pickle.dump(Log_reg, file)\n",
        "        \n",
        "    print(\"Model Trained\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAvBnD5RoU--"
      },
      "source": [
        "def predict(data_path, model_file):\n",
        "    \n",
        "    import pickle\n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import recall_score, accuracy_score\n",
        "    \n",
        "    with open(f'{data_path}/{log_reg_file}','rb') as file:\n",
        "        log_reg = pickle.load(file)\n",
        "\n",
        "    # Load and unpack the test_data\n",
        "    preprocessed_data = np.load(f'{data_path}/preprocessed-data.npz')\n",
        "    x_test = preprocessed_data['xtest']\n",
        "    y_test = preprocessed_data['ytest']\n",
        "\n",
        "    #Evaluate the model and print results\n",
        "    y_multirf = regr_multirf.predict(normalised_test_df)\n",
        "    y_rf = regr_rf.predict(normalised_test_df)\n",
        "\n",
        "    r2 = metrics.r2_score(y_test,y_multirf)\n",
        "    round(r2,2)\n",
        "    \n",
        "    print('Model \\nr2 score = {}' .format(metrics.r2_score(y_test,y_multirf))\n",
        "    \n",
        "    #np.savetxt(f'{data_path}/model_result.txt', clf_pred, fmt='%1.2f')\n",
        "    with open(f'{data_path}/model_result.txt', 'w') as result:\n",
        "        result.write(\" Prediction: {},\\nActual: {} \".format(log_reg_pred,y_test))\n",
        "    \n",
        "    print('Prediction has been saved successfully!')\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4BapMR0oU_b"
      },
      "source": [
        "train_op = comp.func_to_container_op(train , base_image = \"python:3.7-slim\")\n",
        "predict_op = comp.func_to_container_op(predict , base_image = \"python:3.7-slim\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrsb7SYeoU_r",
        "outputId": "c657884b-3868-4ed3-8e0c-6aa845593900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "client = kfp.Client()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to load kube config.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIhB1Q9hoU_1"
      },
      "source": [
        "# Define the pipeline\n",
        "@dsl.pipeline(\n",
        "   name='Presidential Elections Pipeline',\n",
        "   description='An ML pipeline that predicts outcome of presidential elections.'\n",
        ")\n",
        "\n",
        "# Define parameters to be fed into pipeline\n",
        "def presidential_election_pipeline(\n",
        "    data_path: str,\n",
        "    log_reg_file: str\n",
        "):\n",
        "    \n",
        "    # Define volume to share data between components.\n",
        "    vop = dsl.VolumeOp(\n",
        "    name=\"create_volume\",\n",
        "    resource_name=\"data-volume\", \n",
        "    size=\"1Gi\", \n",
        "    modes=dsl.VOLUME_MODE_RWO)\n",
        "    \n",
        "    # Create presidential elections training component.\n",
        "    presidential_elections_training_container = train_op(data_path, model_file) \\\n",
        "                                    .add_pvolumes({data_path: vop.volume})\n",
        "\n",
        "    # Create presidential elections prediction component.\n",
        "    presidential_elections_predict_container = predict_op(data_path, model_file) \\\n",
        "                                    .add_pvolumes({data_path: presidential_elections_training_container.pvolume})\n",
        "    \n",
        "    # Print the result of the prediction\n",
        "    presidential_elections_result_container = dsl.ContainerOp(\n",
        "        name=\"print_prediction\",\n",
        "        image='library/bash:4.4.23',\n",
        "        pvolumes={data_path: presidential_elections_predict_container.pvolume},\n",
        "        arguments=['cat', f'{data_path}/result.txt']\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZvGbCBKoVAB"
      },
      "source": [
        "DATA_PATH = '/mnt'\n",
        "MODEL_PATH='presidential_elections_model.h5'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87kVCm52oVAO",
        "outputId": "6669af17-9d33-47c8-8166-188f7f14298d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "pipeline_func = presidential_elections_container_pipeline"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-54edaddf37cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresidential_elections_container_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'presidential_elections_container_pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRIDytHioVAg"
      },
      "source": [
        "run_name = pipeline_func.__name__ + ' run'\n",
        "\n",
        "arguments = {\"data_path\":DATA_PATH,\n",
        "             \"model_file\":MODEL_PATH}\n",
        "\n",
        "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
        "kfp.compiler.Compiler().compile(pipeline_func,  \n",
        "  '{}.zip'.format(experiment_name))\n",
        "\n",
        "# Submit pipeline directly from pipeline function\n",
        "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
        "                                                  experiment_name=experiment_name, \n",
        "                                                  run_name=run_name, \n",
        "                                                  arguments=arguments)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}