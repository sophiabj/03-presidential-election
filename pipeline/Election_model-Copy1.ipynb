{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "\n",
    "!pip3 install pandas==0.23.4 matplotlib==3.0.3 scipy==1.2.1 scikit-learn==0.22  --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kfp --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which dsl-compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/home/jovyan/Artificial-Neural-Network/data/out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_path, model_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "    import os\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import recall_score, accuracy_score\n",
    "    \n",
    "    df = pd.read_csv('https://github.com/sophiabj/03-presidential-election/blob/master/data/president-1976-2016.csv')\n",
    "    new_dataframe = df[(df.party=='republican') + (df.party =='democrat')]\n",
    "    \n",
    "    new_dataframe.drop(['state_ic','notes','state','state_po', 'office','writein','candidate'],inplace=True, axis = 1)\n",
    "    \n",
    "    X = new_dataframe.drop('party', axis=1)\n",
    "    y = new_dataframe['party']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    normalised_train_df = scaler.fit_transform(x_train)\n",
    "    normalised_train_df = pd.DataFrame(normalised_train_df, columns=x_train.columns)\n",
    "\n",
    "    normalised_test_df = scaler.transform(x_test)\n",
    "    normalised_test_df = pd.DataFrame(normalised_test_df, columns=x_train.columns)\n",
    "\n",
    "\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(normalised_train_df, y_train)\n",
    "    \n",
    "    test_loss, test_acc = log_reg.evaluate(normalised_test_df,  y_test, verbose=0)\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "    #Save the model to the designated \n",
    "    log_reg.save(f'{data_path}/{model_file}')\n",
    "\n",
    "    #Save the test_data as a pickle file to be used by the predict component.\n",
    "    with open(f'{data_path}/test_data', 'wb') as f:\n",
    "        pickle.dump((normalised_test_df,  y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = train(out_dir, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70 101]\n",
      " [ 79  87]]\n"
     ]
    }
   ],
   "source": [
    "def predict(data_path, model_file):\n",
    "    \n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import recall_score, accuracy_score\n",
    "    \n",
    "    log_reg = log_reg.load_model(f'{data_path}/{model_file}')\n",
    "\n",
    "    # Load and unpack the test_data\n",
    "    with open(f'{data_path}/test_data','rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "    # Separate the X_test from y_test.\n",
    "    normalised_test_df,  y_test = test_data\n",
    "\n",
    "    # make predictions.\n",
    "   new_predictions = log_reg.predict(normalised_test_df)\n",
    "    # create a threshold\n",
    "    new_predictions=(new_predictions>0.5)\n",
    "    \n",
    "   cnf_mat = confusion_matrix(y_test, new_predictions)\n",
    "     \n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=new_predictions)\n",
    "   \n",
    "    print('Accuracy: {}'.format(round(accuracy*100), 2))\n",
    "    print(cnf_mat)\n",
    "    \n",
    "     with open(f'{data_path}/result.txt', 'w') as result:\n",
    "        result.write(\" Prediction: {}, Actual: {} \".format(new_predictions,y_test.astype(np.bool)))\n",
    "    \n",
    "    print('Prediction has been saved successfully!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(out_dir, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = comp.func_to_container_op(train , base_image = \"python:3.7-slim\")\n",
    "predict_op = comp.func_to_container_op(predict , base_image = \"python:3.7-slim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='Presidential Elections Pipeline',\n",
    "   description='An ML pipeline that predicts outcome of presidential elections.'\n",
    ")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def presidential_election_pipeline(\n",
    "    data_path: str,\n",
    "    model_file: str\n",
    "):\n",
    "    \n",
    "    # Define volume to share data between components.\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"create_volume\",\n",
    "    resource_name=\"data-volume\", \n",
    "    size=\"1Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    # Create churn training component.\n",
    "    presidential_elections_training_container = train_op(data_path, model_file) \\\n",
    "                                    .add_pvolumes({data_path: vop.volume})\n",
    "\n",
    "    # Create Churn prediction component.\n",
    "    presidential_elections_predict_container = predict_op(data_path, model_file) \\\n",
    "                                    .add_pvolumes({data_path: presidential_elections_training_container.pvolume})\n",
    "    \n",
    "    # Print the result of the prediction\n",
    "    presidential_elections_result_container = dsl.ContainerOp(\n",
    "        name=\"print_prediction\",\n",
    "        image='library/bash:4.4.23',\n",
    "        pvolumes={data_path: presidential_elections_predict_container.pvolume},\n",
    "        arguments=['cat', f'{data_path}/result.txt']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt'\n",
    "MODEL_PATH='presidential_elections_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = presidential_elections_container_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = pipeline_func.__name__ + ' run'\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH,\n",
    "             \"model_file\":MODEL_PATH}\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "  '{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
